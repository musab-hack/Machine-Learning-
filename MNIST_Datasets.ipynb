{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNIST Datasets",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPZ56reoTjOjMqxTXO6JNY9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/musab-hack/Machine-Learning-/blob/master/MNIST_Datasets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zBT67oPTZqlP",
        "colab_type": "text"
      },
      "source": [
        "# Machine Learning with MNIST datasets, Complete Tutorial with Explanation\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6rrQDN7G8QBu",
        "colab_type": "text"
      },
      "source": [
        "## Some Important Points to Note down!!!!\n",
        "\n",
        "\n",
        "**1)** You can either define a utility function (or fitness function) that measures how good your model is, or you can define a **cost function** that measures how bad it is.\n",
        "\n",
        "**2)** For **linear regression problems**, people\n",
        "typically use a cost function that measures the distance between the linear modelâ€™s predictions and the training examples; the objective is to minimize this distance.\n",
        "\n",
        "URL : https://ibb.co/qrC71qK     (Image)\n",
        "\n",
        "**3)** During Clearning of data some instances are clearly outliers, it may help to simply discard them\n",
        "\n",
        "**4)** ***Overfitting the Training Data***: In Machine Learning this is called overfitting: it means that the model performs well on the training data, but it does not generalize well.\n",
        "\n",
        "**5)** Regularization reduces the risk of overfitting of datasets and it can be controlled by the hyperparameter\n",
        "\n",
        "**6)** Important concept about **Non-Linear Regression** and **Linear Regression**\n",
        "https://www.javatpoint.com/machine-learning-polynomial-regression#:~:text=ML%20Polynomial%20Regression&text=It%20is%20also%20called%20the,order%20to%20increase%20the%20accuracy.\n",
        "\n",
        "**7)** Be aware about the Nonlinear Datasets and Linear Datasets\n",
        "\n",
        "**8)** For the best choice of the model you can use the Cross Validation "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eVq0fd2Sd-SP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RisBNfGpd-Xj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.datasets import fetch_openml"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jyHil7D0d-Vl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mnist = fetch_openml('mnist_784' , version=1)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RuqJ34Czwe73",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "80495730-4b06-4345-ab70-45847428f521"
      },
      "source": [
        "data , target = mnist[\"data\"] , mnist[\"target\"]\n",
        "data[1] # Single Pixel"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "         0.,   0.,   0.,   0.,   0.,   0.,  51., 159., 253., 159.,  50.,\n",
              "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "        48., 238., 252., 252., 252., 237.,   0.,   0.,   0.,   0.,   0.,\n",
              "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "         0.,   0.,   0.,   0.,   0.,  54., 227., 253., 252., 239., 233.,\n",
              "       252.,  57.,   6.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,  10.,  60.,\n",
              "       224., 252., 253., 252., 202.,  84., 252., 253., 122.,   0.,   0.,\n",
              "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "         0.,   0.,   0.,   0., 163., 252., 252., 252., 253., 252., 252.,\n",
              "        96., 189., 253., 167.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,  51., 238.,\n",
              "       253., 253., 190., 114., 253., 228.,  47.,  79., 255., 168.,   0.,\n",
              "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "         0.,   0.,   0.,  48., 238., 252., 252., 179.,  12.,  75., 121.,\n",
              "        21.,   0.,   0., 253., 243.,  50.,   0.,   0.,   0.,   0.,   0.,\n",
              "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,  38., 165., 253.,\n",
              "       233., 208.,  84.,   0.,   0.,   0.,   0.,   0.,   0., 253., 252.,\n",
              "       165.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "         0.,   0.,   7., 178., 252., 240.,  71.,  19.,  28.,   0.,   0.,\n",
              "         0.,   0.,   0.,   0., 253., 252., 195.,   0.,   0.,   0.,   0.,\n",
              "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,  57., 252., 252.,\n",
              "        63.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0., 253.,\n",
              "       252., 195.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "         0.,   0.,   0., 198., 253., 190.,   0.,   0.,   0.,   0.,   0.,\n",
              "         0.,   0.,   0.,   0.,   0., 255., 253., 196.,   0.,   0.,   0.,\n",
              "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,  76., 246., 252.,\n",
              "       112.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "       253., 252., 148.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "         0.,   0.,   0.,  85., 252., 230.,  25.,   0.,   0.,   0.,   0.,\n",
              "         0.,   0.,   0.,   0.,   7., 135., 253., 186.,  12.,   0.,   0.,\n",
              "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,  85., 252.,\n",
              "       223.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   7., 131.,\n",
              "       252., 225.,  71.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "         0.,   0.,   0.,   0.,  85., 252., 145.,   0.,   0.,   0.,   0.,\n",
              "         0.,   0.,   0.,  48., 165., 252., 173.,   0.,   0.,   0.,   0.,\n",
              "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,  86.,\n",
              "       253., 225.,   0.,   0.,   0.,   0.,   0.,   0., 114., 238., 253.,\n",
              "       162.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "         0.,   0.,   0.,   0.,   0.,  85., 252., 249., 146.,  48.,  29.,\n",
              "        85., 178., 225., 253., 223., 167.,  56.,   0.,   0.,   0.,   0.,\n",
              "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "        85., 252., 252., 252., 229., 215., 252., 252., 252., 196., 130.,\n",
              "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "         0.,   0.,   0.,   0.,   0.,   0.,  28., 199., 252., 252., 253.,\n",
              "       252., 252., 233., 145.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "         0.,   0.,  25., 128., 252., 253., 252., 141.,  37.,   0.,   0.,\n",
              "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "         0.,   0.,   0.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s5k5KkVIwfBm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fa5d9284-a1aa-4ed6-81f3-024ac7ecb148"
      },
      "source": [
        "data.shape # Print the rows and columns of the data"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(70000, 784)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BNt917V6xz-7",
        "colab_type": "text"
      },
      "source": [
        "There are 70,000 images, and each image has 784 features. This is because each image is 28Ã—28 pixels, and each feature simply represents one pixelâ€™s intensity, from 0 (white) to 255 (black)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WtBM3J_6we_c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "7622e941-cfa4-4574-bf91-638e30e75082"
      },
      "source": [
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "digit = data[50]\n",
        "digit = digit.reshape(28 , 28)\n",
        "\n",
        "plt.imshow(digit , cmap = mpl.cm.binary , interpolation=\"nearest\")\n",
        "plt.show()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ovT6CWWJy_m7",
        "colab_type": "text"
      },
      "source": [
        "Note that the label is a string, we need to convert into int \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sdEWqUeexkks",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d811c428-7ee2-4256-cab4-eb4003a3bd3f"
      },
      "source": [
        "target = target.astype(np.uint8)\n",
        "target"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 0, 4, ..., 4, 5, 6], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qrYaRPxj0LA1",
        "colab_type": "text"
      },
      "source": [
        "You should always create a test set and set it aside before inspecting the data\n",
        "closely. The MNIST dataset is actually already split into a training set (the first 60,000\n",
        "images) and a test set (the last 10,000 images):\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PisR4Secxkqg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_test_split(data , split_num):\n",
        "  shuffled_indices = np.random.permutation(len(data))\n",
        "  test_num = int(len(shuffled_indices)*split_num)\n",
        "  test_data_indices = shuffled_indices[:test_num]\n",
        "  train_data_indices = shuffled_indices[test_num:]\n",
        "  return data[test_data_indices] , data[train_data_indices]"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AFXcrzMZxkzu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert numpy array to pandas\n",
        "# data = pd.DataFrame(data = data) but it will takw too much space\n",
        "\n",
        "test_data , train_data = train_test_split(data , 0.12)"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XcpKfUHBxktx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "10e5f8ea-7868-4d8c-ad28-af4657b3b026"
      },
      "source": [
        "print(\"Shape Of Test Data\" , test_data.shape)\n",
        "print(\"Shape of train Data\" , train_data.shape)"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape Of Test Data (8400, 784)\n",
            "Shape of train Data (61600, 784)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XElRrcc2_jZ5",
        "colab_type": "text"
      },
      "source": [
        "# **Training The Binary Classifier**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ljB1524-xkoB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}